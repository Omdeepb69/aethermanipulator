{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AetherManipulator - Gesture Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Generation (Simulated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we don't have a pre-collected dataset of hand landmarks mapped to gestures (translate, rotate, scale), we'll generate synthetic data for demonstration purposes. In a real scenario, you would collect data using MediaPipe, extract relevant features (e.g., distances between landmarks, angles, hand openness), and label them according to the intended gesture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_synthetic_data(n_samples=1000, n_features=42):\n",
        "    \"\"\"Generates synthetic data simulating hand landmark features.\n",
        "    \n",
        "    Args:\n",
        "        n_samples (int): Number of data points to generate.\n",
        "        n_features (int): Number of features (e.g., 21 landmarks * 2 coords).\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (X, y) - features and labels.\n",
        "    \"\"\"\n",
        "    # Simulate features (e.g., normalized landmark coordinates relative to wrist)\n",
        "    X = np.random.rand(n_samples, n_features) \n",
        "    \n",
        "    # Simulate labels (0: translate, 1: rotate, 2: scale)\n",
        "    # Assign labels based on some arbitrary feature patterns for reproducibility\n",
        "    y = np.zeros(n_samples, dtype=int)\n",
        "    \n",
        "    # Rule 1: High sum of first 10 features -> Rotate (fist-like)\n",
        "    mask_rotate = X[:, :10].sum(axis=1) > 5\n",
        "    y[mask_rotate] = 1\n",
        "    \n",
        "    # Rule 2: High variance in last 10 features -> Scale (two hands / spread?)\n",
        "    # Ensure we only modify non-rotate samples\n",
        "    mask_scale = (X[:, -10:].var(axis=1) > 0.08) & (~mask_rotate)\n",
        "    y[mask_scale] = 2\n",
        "    \n",
        "    # Remaining samples are Translate (default 0)\n",
        "    \n",
        "    print(f\"Generated {n_samples} samples.\")\n",
        "    print(f\"Class distribution: {np.bincount(y)}\")\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "# Generate data\n",
        "X, y = generate_synthetic_data(n_samples=2000, n_features=42) # 21 landmarks * 2 coords (x, y)\n",
        "\n",
        "# Create a DataFrame (optional, but good practice)\n",
        "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['label'] = y\n",
        "\n",
        "print(\"\\nSample data head:\")\n",
        "print(df.head())\n",
        "print(\"\\nData shape:\")\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Splitting and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and labels\n",
        "X = df.drop('label', axis=1).values\n",
        "y = df['label'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"Testing set shape: X={X_test.shape}, y={y_test.shape}\")\n",
        "\n",
        "# Define preprocessing steps (Standard Scaling)\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Definition and Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the model (Random Forest Classifier)\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a pipeline including scaling and the model\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', scaler),\n",
        "    ('classifier', model)\n",
        "])\n",
        "\n",
        "# Train the basic pipeline\n",
        "print(\"Training the initial model...\")\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"Initial model training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Hyperparameter Tuning (Grid Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the parameter grid for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [50, 100, 200], # Number of trees\n",
        "    'classifier__max_depth': [None, 10, 20],    # Maximum depth of trees\n",
        "    'classifier__min_samples_split': [2, 5],   # Min samples to split node\n",
        "    'classifier__min_samples_leaf': [1, 3]     # Min samples in leaf node\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "# cv=3 for faster execution, use cv=5 or more for better results\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n",
        "\n",
        "print(\"Starting Hyperparameter Tuning (GridSearchCV)...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nGridSearchCV complete.\")\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Get the best estimator\n",
        "best_model_pipeline = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the best model on the test set\n",
        "y_pred = best_model_pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nTest Set Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "class_names = ['Translate (0)', 'Rotate (1)', 'Scale (2)']\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot Learning Curve\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    best_model_pipeline, X, y, cv=3, n_jobs=-1, \n",
        "    train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'\n",
        ")\n",
        "\n",
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                 color=\"r\")\n",
        "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "         label=\"Training score\")\n",
        "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "         label=\"Cross-validation score\")\n",
        "\n",
        "plt.xlabel(\"Training examples\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the filename for the saved model\n",
        "model_filename = 'aether_manipulator_gesture_model.joblib'\n",
        "\n",
        "# Save the entire pipeline (including scaler and model)\n",
        "joblib.dump(best_model_pipeline, model_filename)\n",
        "\n",
        "print(f\"\\nModel pipeline saved to {model_filename}\")\n",
        "\n",
        "# Example of loading the model back (for verification)\n",
        "loaded_pipeline = joblib.load(model_filename)\n",
        "print(\"\\nModel pipeline loaded successfully.\")\n",
        "\n",
        "# Verify loaded model by predicting a sample\n",
        "sample_pred = loaded_pipeline.predict(X_test[0].reshape(1, -1))\n",
        "print(f\"Prediction for first test sample: {sample_pred[0]} (True label: {y_test[0]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End of Training Notebook"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}