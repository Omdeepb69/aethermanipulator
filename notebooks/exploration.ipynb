{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "```json\n{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import numpy as np\\n\",\n    \"import pandas as pd\\n\",\n    \"import matplotlib.pyplot as plt\\n\",\n    \"import seaborn as sns\\n\",\n    \"from sklearn.model_selection import train_test_split\\n\",\n    \"from sklearn.preprocessing import StandardScaler, LabelEncoder\\n\",\n    \"from sklearn.linear_model import LogisticRegression\\n\",\n    \"from sklearn.svm import SVC\\n\",\n    \"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\\n\",\n    \"import itertools\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Simulate Hand Landmark Data Generation\\n\",\n    \"NUM_LANDMARKS = 21\\n\",\n    \"NUM_SAMPLES_PER_GESTURE = 200\\n\",\n    \"GESTURES = ['Open_Hand', 'Closed_Fist', 'Pinch']\\n\",\n    \"NOISE_LEVEL = 0.03\\n\",\n    \"\\n\",\n    \"def generate_base_pose(gesture):\\n\",\n    \"    # Simplified canonical poses (relative to wrist at origin)\\n\",\n    \"    pose = np.zeros((NUM_LANDMARKS, 3))\\n\",\n    \"    # Wrist\\n\",\n    \"    pose[0] = [0, 0, 0]\\n\",\n    \"    \\n\",\n    \"    if gesture == 'Open_Hand':\\n\",\n    \"        # Thumb\\n\",\n    \"        pose[1] = [0.05, -0.02, 0.01]\\n\",\n    \"        pose[2] = [0.1, -0.04, 0.02]\\n\",\n    \"        pose[3] = [0.15, -0.06, 0.03]\\n\",\n    \"        pose[4] = [0.2, -0.08, 0.04]\\n\",\n    \"        # Index\\n\",\n    \"        pose[5] = [0.01, 0.05, 0]\\n\",\n    \"        pose[6] = [0.02, 0.1, 0]\\n\",\n    \"        pose[7] = [0.03, 0.15, 0]\\n\",\n    \"        pose[8] = [0.04, 0.2, 0]\\n\",\n    \"        # Middle\\n\",\n    \"        pose[9] = [0, 0.06, 0]\\n\",\n    \"        pose[10] = [0, 0.12, 0]\\n\",\n    \"        pose[11] = [0, 0.18, 0]\\n\",\n    \"        pose[12] = [0, 0.24, 0]\\n\",\n    \"        # Ring\\n\",\n    \"        pose[13] = [-0.01, 0.05, 0]\\n\",\n    \"        pose[14] = [-0.02, 0.1, 0]\\n\",\n    \"        pose[15] = [-0.03, 0.15, 0]\\n\",\n    \"        pose[16] = [-0.04, 0.2, 0]\\n\",\n    \"        # Pinky\\n\",\n    \"        pose[17] = [-0.02, 0.04, 0]\\n\",\n    \"        pose[18] = [-0.04, 0.08, 0]\\n\",\n    \"        pose[19] = [-0.06, 0.12, 0]\\n\",\n    \"        pose[20] = [-0.08, 0.16, 0]\\n\",\n    \"        \\n\",\n    \"    elif gesture == 'Closed_Fist':\\n\",\n    \"        # Thumb (folded)\\n\",\n    \"        pose[1] = [0.03, 0.01, 0.02]\\n\",\n    \"        pose[2] = [0.05, 0.03, 0.04]\\n\",\n    \"        pose[3] = [0.06, 0.05, 0.06]\\n\",\n    \"        pose[4] = [0.07, 0.07, 0.08]\\n\",\n    \"        # Fingers curled\\n\",\n    \"        pose[5] = [0.01, 0.05, 0.01]\\n\",\n    \"        pose[6] = [0.02, 0.08, 0.03]\\n\",\n    \"        pose[7] = [0.03, 0.08, 0.06]\\n\",\n    \"        pose[8] = [0.04, 0.08, 0.09]\\n\",\n    \"        pose[9] = [0, 0.06, 0.01]\\n\",\n    \"        pose[10] = [0, 0.09, 0.03]\\n\",\n    \"        pose[11] = [0, 0.09, 0.06]\\n\",\n    \"        pose[12] = [0, 0.09, 0.09]\\n\",\n    \"        pose[13] = [-0.01, 0.05, 0.01]\\n\",\n    \"        pose[14] = [-0.02, 0.08, 0.03]\\n\",\n    \"        pose[15] = [-0.03, 0.08, 0.06]\\n\",\n    \"        pose[16] = [-0.04, 0.08, 0.09]\\n\",\n    \"        pose[17] = [-0.02, 0.04, 0.01]\\n\",\n    \"        pose[18] = [-0.04, 0.07, 0.03]\\n\",\n    \"        pose[19] = [-0.05, 0.07, 0.06]\\n\",\n    \"        pose[20] = [-0.06, 0.07, 0.09]\\n\",\n    \"        \\n\",\n    \"    elif gesture == 'Pinch': # Thumb and Index finger tips close\\n\",\n    \"        # Thumb\\n\",\n    \"        pose[1] = [0.04, -0.01, 0.01]\\n\",\n    \"        pose[2] = [0.08, -0.02, 0.02]\\n\",\n    \"        pose[3] = [0.12, -0.03, 0.03]\\n\",\n    \"        pose[4] = [0.15, 0.02, 0.04] # Tip closer to index\\n\",\n    \"        # Index\\n\",\n    \"        pose[5] = [0.01, 0.05, 0]\\n\",\n    \"        pose[6] = [0.02, 0.1, 0]\\n\",\n    \"        pose[7] = [0.03, 0.13, 0.01]\\n\",\n    \"        pose[8] = [0.13, 0.03, 0.03] # Tip closer to thumb\\n\",\n    \"        # Other fingers slightly open/relaxed\\n\",\n    \"        pose[9] = [0, 0.06, 0]\\n\",\n    \"        pose[10] = [0, 0.12, 0]\\n\",\n    \"        pose[11] = [0, 0.18, 0]\\n\",\n    \"        pose[12] = [0, 0.22, 0]\\n\",\n    \"        pose[13] = [-0.01, 0.05, 0]\\n\",\n    \"        pose[14] = [-0.02, 0.1, 0]\\n\",\n    \"        pose[15] = [-0.03, 0.15, 0]\\n\",\n    \"        pose[16] = [-0.04, 0.19, 0]\\n\",\n    \"        pose[17] = [-0.02, 0.04, 0]\\n\",\n    \"        pose[18] = [-0.04, 0.08, 0]\\n\",\n    \"        pose[19] = [-0.06, 0.12, 0]\\n\",\n    \"        pose[20] = [-0.08, 0.15, 0]\\n\",\n    \"        \\n\",\n    \"    return pose\\n\",\n    \"\\n\",\n    \"data = []\\n\",\n    \"labels = []\\n\",\n    \"\\n\",\n    \"for gesture in GESTURES:\\n\",\n    \"    base_pose = generate_base_pose(gesture)\\n\",\n    \"    for _ in range(NUM_SAMPLES_PER_GESTURE):\\n\",\n    \"        noisy_pose = base_pose + np.random.normal(0, NOISE_LEVEL, base_pose.shape)\\n\",\n    \"        # Simulate overall hand position/orientation variance\\n\",\n    \"        offset = np.random.rand(3) * 0.1 # Small random offset\\n\",\n    \"        noisy_pose += offset\\n\",\n    \"        data.append(noisy_pose.flatten()) # Flatten landmarks into a single feature vector\\n\",\n    \"        labels.append(gesture)\\n\",\n    \"\\n\",\n    \"# Create DataFrame\\n\",\n    \"feature_names = [f'landmark_{i}_{coord}' for i in range(NUM_LANDMARKS) for coord in ['x', 'y', 'z']]\\n\",\n    \"df = pd.DataFrame(data, columns=feature_names)\\n\",\n    \"df['gesture'] = labels\\n\",\n    \"\\n\",\n    \"# Shuffle DataFrame\\n\",\n    \"df = df.sample(frac=1).reset_index(drop=True)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Data Inspection\\n\",\n    \"print(\\\"First 5 rows:\\\")\\n\",\n    \"print(df.head())\\n\",\n    \"print(\\\"\\\\nDataFrame Info:\\\")\\n\",\n    \"df.info()\\n\",\n    \"print(\\\"\\\\nDescriptive Statistics:\\\")\\n\",\n    \"print(df.describe())\\n\",\n    \"print(\\\"\\\\nGesture Distribution:\\\")\\n\",\n    \"print(df['gesture'].value_counts())\\n\",\n    \"print(\\\"\\\\nCheck for Missing Values:\\\")\\n\",\n    \"print(df.isnull().sum().sum())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# EDA - Distributions\\n\",\n    \"plt.figure(figsize=(12, 6))\\n\",\n    \"sns.histplot(data=df, x='landmark_8_y', hue='gesture', kde=True) # Index finger tip Y coordinate\\n\",\n    \"plt.title('Distribution of Index Finger Tip Y-coordinate by Gesture')\\n\",\n    \"plt.show()\\n\",\n    \"\\n\",\n    \"plt.figure(figsize=(12, 6))\\n\",\n    \"sns.histplot(data=df, x='landmark_4_x', hue='gesture', kde=True) # Thumb tip X coordinate\\n\",\n    \"plt.title('Distribution of Thumb Tip X-coordinate by Gesture')\\n\",\n    \"plt.show()\\n\",\n    \"\\n\",\n    \"# Select a few landmark coordinates for pairplot\\n\",\n    \"sample_features = ['landmark_4_x', 'landmark_4_y', 'landmark_8_x', 'landmark_8_y', 'landmark_12_y', 'gesture']\\n\",\n    \"sns.pairplot(df[sample_features], hue='gesture', diag_kind='kde')\\n\",\n    \"plt.suptitle('Pairplot of Selected Landmark Coordinates', y=1.02)\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# EDA - Visualization of Hand Skeletons (2D Projection)\\n\",\n    \"\\n\",\n    \"# Define connections between landmarks for plotting\\n\",\n    \"HAND_CONNECTIONS = [\\n\",\n    \"    (0, 1), (1, 2), (2, 3), (3, 4),         # Thumb\\n\",\n    \"    (0, 5), (5, 6), (6, 7), (7, 8),         # Index finger\\n\",\n    \"    (0, 9), (9, 10), (10, 11), (11, 12),    # Middle finger\\n\",\n    \"    (0, 13), (13, 14), (14, 15), (15, 16), # Ring finger\\n\",\n    \"    (0, 17), (17, 18), (18, 19), (19, 20), # Pinky\\n\",\n    \"    (5, 9), (9, 13), (13, 17)              # Palm\\n\",\n    \"]\\n\",\n    \"\\n\",\n    \"def plot_hand_skeleton(landmarks_row, ax, title):\\n\",\n    \"    landmarks = landmarks_row[feature_names].values.reshape(NUM_LANDMARKS, 3)\\n\",\n    \"    # Use x and y for 2D plot, invert y for typical image coordinates\\n\",\n    \"    x = landmarks[:, 0]\\n\",\n    \"    y = -landmarks[:, 1] \\n\",\n    \"    \\n\",\n    \"    ax.scatter(x, y, s=10, c='red')\\n\",\n    \"    for connection in HAND_CONNECTIONS:\\n\",\n    \"        start_idx, end_idx = connection\\n\",\n    \"        if start_idx < NUM_LANDMARKS and end_idx < NUM_LANDMARKS:\\n\",\n    \"             ax.plot([x[start_idx], x[end_idx]], [y[start_idx], y[end_idx]], 'blue')\\n\",\n    \"                \\n\",\n    \"    ax.set_title(title)\\n\",\n    \"    ax.set_xlabel('X')\\n\",\n    \"    ax.set_ylabel('Y')\\n\",\n    \"    ax.set_aspect('equal', adjustable='box')\\n\",\n    \"    ax.invert_yaxis() # Match typical image coordinate system if needed\\n\",\n    \"\\n\",\n    \"fig, axes = plt.subplots(1, len(GESTURES), figsize=(15, 5))\\n\",\n    \"for i, gesture in enumerate(GESTURES):\\n\",\n    \"    sample = df[df['gesture'] == gesture].iloc[0] # Take the first sample for each gesture\\n\",\n    \"    plot_hand_skeleton(sample, axes[i], f'Example: {gesture}')\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Statistical Analysis\\n\",\n    \"# Calculate mean landmark positions for each gesture\\n\",\n    \"mean_landmarks = df.groupby('gesture').mean()\\n\",\n    \"print(\\\"Mean Landmark Coordinates per Gesture:\\\")\\n\",\n    \"print(mean_landmarks)\\n\",\n    \"\\n\",\n    \"# Calculate standard deviation for a specific landmark (e.g., index tip y)\\n\",\n    \"std_dev_index_y = df.groupby('gesture')['landmark_8_y'].std()\\n\",\n    \"print(\\\"\\\\nStandard Deviation of Index Tip Y-coordinate per Gesture:\\\")\\n\",\n    \"print(std_dev_index_y)\\n\",\n    \"\\n\",\n    \"# Correlation matrix (only for a subset of features due to high dimensionality)\\n\",\n    \"subset_features = ['landmark_4_x', 'landmark_4_y', 'landmark_8_x', 'landmark_8_y', 'landmark_12_x', 'landmark_12_y']\\n\",\n    \"correlation_matrix = df[subset_features].corr()\\n\",\n    \"plt.figure(figsize=(10, 8))\\n\",\n    \"sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\\n\",\n    \"plt.title('Correlation Matrix of Selected Landmark Coordinates')\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Feature Engineering Experiments\\n\",\n    \"\\n\",\n    \"def calculate_distances(landmarks):\\n\",\n    \"    # Calculate distance between thumb tip (4) and index tip (8)\\n\",\n    \"    dist_thumb_index = np.linalg.norm(landmarks[4] - landmarks[8])\\n\",\n    \"    # Calculate distance between index tip (8) and middle tip (12)\\n\",\n    \"    dist_index_middle = np.linalg.norm(landmarks[8] - landmarks[12])\\n\",\n    \"    # Calculate average distance of fingertips (4, 8, 12, 16, 20) to wrist (0)\\n\",\n    \"    fingertip_indices = [4, 8, 12, 16, 20]\\n\",\n    \"    avg_dist_fingertips_wrist = np.mean([np.linalg.norm(landmarks[i] - landmarks[0]) for i in fingertip_indices])\\n\",\n    \"    return pd.Series([dist_thumb_index, dist_index_middle, avg_dist_fingertips_wrist])\\n\",\n    \"\\n\",\n    \"def normalize_landmarks(landmarks):\\n\",\n    \"    # Normalize relative to wrist (landmark 0)\\n\",\n    \"    wrist_pos = landmarks[0]\\n\",\n    \"    relative_landmarks = landmarks - wrist_pos\\n\",\n    \"    \\n\",\n    \"    # Optional: Scale based on a reference distance (e.g., wrist to middle finger base)\\n\",\n    \"    ref_distance = np.linalg.norm(relative_landmarks[9] - relative_landmarks[0])\\n\",\n    \"    if ref_distance > 1e-6: # Avoid division by zero\\n\",\n    \"         normalized_landmarks = relative_landmarks / ref_distance\\n\",\n    \"    else:\\n\",\n    \"         normalized_landmarks = relative_landmarks\\n\",\n    \"            \\n\",\n    \"    return normalized_landmarks.flatten()\\n\",\n    \"\\n\",\n    \"# Apply distance calculation\\n\",\n    \"landmark_data = df[feature_names].values.reshape(-1, NUM_LANDMARKS, 3)\\n\",\n    \"distances_df = pd.DataFrame([calculate_distances(lm) for lm in landmark_data])\\n\",\n    \"distances_df.columns = ['dist_thumb_index', 'dist_index_middle', 'avg_dist_fingertips_wrist']\\n\",\n    \"\\n\",\n    \"# Apply normalization\\n\",\n    \"normalized_data = np.array([normalize_landmarks(lm) for lm in landmark_data])\\n\",\n    \"normalized_feature_names = [f'norm_lm_{i}_{coord}' for i in range(NUM_LANDMARKS) for coord in ['x', 'y', 'z']]\\n\",\n    \"normalized_df = pd.DataFrame(normalized_data, columns=normalized_feature_names)\\n\",\n    \"\\n\",\n    \"# Combine engineered features with original data (or create a new feature DataFrame)\\n\",\n    \"df_features = pd.concat([df['gesture'], distances_df, normalized_df], axis=1)\\n\",\n    \"\\n\",\n    \"print(\\\"DataFrame with Engineered Features (Head):\\\")\\n\",\n    \"print(df_features.head())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Re-inspect Data with Engineered Features\\n\",\n    \"print(\\\"\\\\nEngineered Features Info:\\\")\\n\",\n    \"df_features.info()\\n\",\n    \"\\n\",\n    \"print(\\\"\\\\nEngineered Features Description:\\\")\\n\",\n    \"print(df_features[['dist_thumb_index', 'dist_index_middle', 'avg_dist_fingertips_wrist']].describe())\\n\",\n    \"\\n\",\n    \"plt.figure(figsize=(15, 5))\\n\",\n    \"plt.subplot(1, 3, 1)\\n\",\n    \"sns.boxplot(data=df_features, x='gesture', y='dist_thumb_index')\\n\",\n    \"plt.title('Thumb-Index Tip Distance')\\n\",\n    \"\\n\",\n    \"plt.subplot(1, 3, 2)\\n\",\n    \"sns.boxplot(data=df_features, x='gesture', y='dist_index_middle')\\n\",\n    \"plt.title('Index-Middle Tip Distance')\\n\",\n    \"\\n\",\n    \"plt.subplot(1, 3, 3)\\n\",\n    \"sns.boxplot(data=df_features, x='gesture', y='avg_dist_fingertips_wrist')\\n\",\n    \"plt.title('Avg Fingertip-Wrist Distance')\\n\",\n    \"\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Initial Model Testing - Preparation\\n\",\n    \"\\n\",\n    \"# Option 1: Use only engineered distance features\\n\",\n    \"# X = df_features[['dist_thumb_index', 'dist_index_middle', 'avg_dist_fingertips_wrist']]\\n\",\n    \"\\n\",\n    \"# Option 2: Use normalized landmark features (potentially better but higher dim)\\n\",\n    \"X = df_features.drop('gesture', axis=1) # Use all engineered features (distances + normalized coords)\\n\",\n    \"# X = normalized_df # Use only normalized coordinates\\n\",\n    \"\\n\",\n    \"y = df_features['gesture']\\n\",\n    \"\\n\",\n    \"# Encode labels\\n\",\n    \"le = LabelEncoder()\\n\",\n    \"y_encoded = le.fit_transform(y)\\n\",\n    \"print(f\\\"Label Encoding: {list(le.classes_)} -> {list(range(len(le.classes_)))}\\\")\\n\",\n    \"\\n\",\n    \"# Split data\\n\",\n    \"X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\\n\",\n    \"\\n\",\n    \"# Scale features\\n\",\n    \"scaler = StandardScaler()\\n\",\n    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n    \"X_test_scaled = scaler.transform(X_test)\\n\",\n    \"\\n\",\n    \"print(f\\\"\\\\nTraining data shape: {X_train_scaled.shape}\\\")\\n\",\n    \"print(f\\\"Testing data shape: {X_test_scaled.shape}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Initial Model Testing - Training (Logistic Regression)\\n\",\n    \"log_reg = LogisticRegression(random_state=42, max_iter=1000)\\n\",\n    \"log_reg.fit(X_train_scaled, y_train)\\n\",\n    \"print(\\\"Logistic Regression Model Trained.\\\")\\n\",\n    \"\\n\",\n    \"# Initial Model Testing - Training (Support Vector Machine)\\n\",\n    \"svm_clf = SVC(random_state=42, probability=True) # probability=True for consistency if needed later\\n\",\n    \"svm_clf.fit(X_train_scaled, y_train)\\n\",\n    \"print(\\\"SVM Classifier Model Trained.\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Initial Model Testing - Evaluation\\n\",\n    \"\\n\",\n    \"def evaluate_model(model, X_test_scaled, y_test, model_name):\\n\",\n    \"    y_pred = model.predict(X_test_scaled)\\n\",\n    \"    accuracy = accuracy_score(y_test, y_pred)\\n\",\n    \"    cm = confusion_matrix(y_test, y_pred)\\n\",\n    \"    cr = classification_report(y_test, y_pred, target_names=le.classes_)\\n\",\n    \"    \\n\",\n    \"    print(f\\\"--- Evaluation Results for {model_name} ---\\\")\\n\",\n    \"    print(f\\\"Accuracy: {accuracy:.4f}\\\")\\n\",\n    \"    print(\\\"\\\\nClassification Report:\\\")\\n\",\n    \"    print(cr)\\n\",\n    \"    print(\\\"\\\\nConfusion Matrix:\\\")\\n\",\n    \"    \\n\",\n    \"    plt.figure(figsize=(6, 5))\\n\",\n    \"    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\\n\",\n    \"    plt.xlabel('Predicted Label')\\n\",\n    \"    plt.ylabel('True Label')\\n\",\n    \"    plt.title(f'{model_name} - Confusion Matrix')\\n\",\n    \"    plt.show()\\n\",\n    \"\\n\",\n    \"evaluate_model(log_reg, X_test_scaled, y_test, \\\"Logistic Regression\\\")\\n\",\n    \"evaluate_model(svm_clf, X_test_scaled, y_test, \\\"SVM Classifier\\\")\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}